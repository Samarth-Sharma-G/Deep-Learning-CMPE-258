## Supervised Contrastive Learning

Supervised Contrastive Learning is performed in two phases:

- Training an encoder to learn to produce vector representations of input images such that representations of images in the same class will be more similar compared to representations of images in different classes.
- Training a classifier on top of the frozen encoder.

Performance of Baseline Model:
![image](https://github.com/Samarth-Sharma-G/Deep-Learning-CMPE-258/assets/107587243/7c61fd73-a06b-46ae-93f7-2c660954723f)

Performance of Model Trained with Supervised Contrastive Learning
![image](https://github.com/Samarth-Sharma-G/Deep-Learning-CMPE-258/assets/107587243/3083aee8-6ff2-4fa2-abc8-f30eaab4f4db)

## Transfer Learning different Modalities

### Image: Transfer Learning using the cifar10 dataset on pre-trained VGG16 model

### Audio: Audio Classification of Nature Sounds in ESC-10 Dataset using Transfer Learning on MobileNetV2
![image](https://github.com/Samarth-Sharma-G/Deep-Learning-CMPE-258/assets/107587243/57f5d1d2-8425-4f03-bf89-c1f4349de077)

### Text: Transfer Learning using textual Sentiment Data on bert_tiny_en_uncased

##  Zero-Shot Transfer Learning 

### Zero-Shot transfer learning with CLIP model on cifar10 dataset
![image](https://github.com/Samarth-Sharma-G/Deep-Learning-CMPE-258/assets/107587243/a5dcb540-7c09-4928-a545-5d0c3606b0b2)

### Transfer learning for mobilenet_v2 on flowers dataset using tfhub

![image](https://github.com/Samarth-Sharma-G/Deep-Learning-CMPE-258/assets/107587243/575636a1-e249-4709-8a78-f58cebd42151)


